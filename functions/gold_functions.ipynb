{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "433f390a-9d39-4fb4-bab6-228a378b191a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_table(df, table_name, layer):\n",
    "    (\n",
    "        df.write.mode(\"append\").format('delta')\n",
    "        .option(\"mergeSchema\", \"true\")    \n",
    "        .option(\"delta.columnMapping.mode\", \"name\")   \n",
    "        .partitionBy(\"ANO_DO_EXERCICIO\", \"BAIRRO\") \n",
    "        .saveAsTable(f\"{layer}_layer.{table_name}\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24c573f6-6760-444c-93ef-ffc0a8637e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ingestao_dados(dados, table_name):\n",
    "\n",
    "    # Leitura dos dados da tabela existente (caso já tinha sido salva anteriormente)\n",
    "    dados_existentes = spark.read.table(f\"gold_layer.{table_name}\")\n",
    "    \n",
    "    # Verificando se os dados importados já existem\n",
    "    verifica_tabela = spark.catalog.tableExists(f\"gold_layer.{table_name}\")\n",
    "\n",
    "    # Se a tabela já existir, realiza filtragem no dataframe importado para inserir apenas os dados novos\n",
    "    if verifica_tabela:         \n",
    "\n",
    "        colunas = dados.columns\n",
    "\n",
    "        condicoes = [dados[c] == dados_existentes[c] for c in colunas]\n",
    "\n",
    "        df_filtrado = dados.join(dados_existentes, on=condicoes, how=\"left_anti\")\n",
    "        \n",
    "        df_filtrado = df_filtrado.dropDuplicates()\n",
    "\n",
    "        print('================================== CARGA DE DADOS ==================================')\n",
    "        print('>> Camada: Gold')\n",
    "        print(f'>> Caminho da tabela silver: silver_layer.{table_name}')\n",
    "        print('>>> Executando carga de dados, aguarde...')\n",
    "\n",
    "        try:        \n",
    "            save_table(df_filtrado, table_name, 'gold')\n",
    "            print('=========================== CARGA FINALIZADA COM SUCESSO ===========================\\n')\n",
    "        except:\n",
    "            print('============================= ERRO NA CARGA DE DADOS... ============================\\n')    \n",
    "\n",
    "    # Caso a tabela não exista, realiza a carga dos dados pela primeira vez\n",
    "    else:        \n",
    "        \n",
    "        print('================================== CARGA DE DADOS ==================================')\n",
    "        print('>> Camada: Gold')\n",
    "        print(f'>> Caminho da tabela silver: silver_layer.{table_name}')\n",
    "        print('>>> Executando carga de dados, aguarde...')\n",
    "\n",
    "        dados = dados.dropDuplicates()\n",
    "\n",
    "        try:        \n",
    "            save_table(dados, table_name, 'gold')\n",
    "            print('=========================== CARGA FINALIZADA COM SUCESSO ===========================\\n')\n",
    "        except:\n",
    "            print('============================= ERRO NA CARGA DE DADOS... ============================\\n')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gold_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}