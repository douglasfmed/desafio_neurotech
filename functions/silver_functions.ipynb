{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95d4c779-24d6-46d4-bd7b-8bc875afe605",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Função para salvar tabela no catálogo"
    }
   },
   "outputs": [],
   "source": [
    "def save_table(df, table_name, layer):\n",
    "    (\n",
    "        df.write.mode(\"append\").format('delta')\n",
    "        .option(\"mergeSchema\", \"true\")    \n",
    "        .option(\"delta.columnMapping.mode\", \"name\")    \n",
    "        .saveAsTable(f\"{layer}_layer.{table_name}\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0bacb7e-05fe-4ea6-9611-f7aae5f33b76",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Função para ajustar os nomes das colunas"
    }
   },
   "outputs": [],
   "source": [
    "def limpar_nome_coluna(nome):\n",
    "\n",
    "    # Remoção de acentos e demais caracteres especiais\n",
    "    nome = re.sub(r'[áàâãä]', 'a', nome, flags=re.IGNORECASE)\n",
    "    nome = re.sub(r'[éèêë]', 'e', nome, flags=re.IGNORECASE)\n",
    "    nome = re.sub(r'[íìîï]', 'i', nome, flags=re.IGNORECASE)\n",
    "    nome = re.sub(r'[óòôõö]', 'o', nome, flags=re.IGNORECASE)\n",
    "    nome = re.sub(r'[úùûü]', 'u', nome, flags=re.IGNORECASE)\n",
    "    nome = re.sub(r'[ç]', 'c', nome, flags=re.IGNORECASE)\n",
    "    nome = re.sub(r'[^\\w\\s]', '', nome)\n",
    "\n",
    "    # Removendo underlines\n",
    "    nome = nome.replace('_', '')\n",
    "\n",
    "    # Troca espaços por underline\n",
    "    nome = nome.replace(' ', '_')\n",
    "\n",
    "    # Retorna o nome da coluna ajustado e em caracteres maiúsculos\n",
    "    return nome.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eff9e86-64fc-49d0-a91a-882b3b26f279",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Função para análise de registros nulos"
    }
   },
   "outputs": [],
   "source": [
    "def analise_nulos(df_teste):\n",
    "\n",
    "    total_linhas = df_teste.count()\n",
    "    print(f\">>> Total de linhas: {total_linhas}\")\n",
    "\n",
    "    # Total de nulos por coluna\n",
    "    nulos_por_coluna = df_teste.select([\n",
    "        sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "        for c in df_teste.columns\n",
    "    ])\n",
    "\n",
    "    nulos_dict = nulos_por_coluna.first().asDict()\n",
    "\n",
    "    for coluna, qtd_nulos in nulos_dict.items():\n",
    "        if(qtd_nulos > 0):\n",
    "            print(f\"{coluna}: {qtd_nulos} registros nulos ({round(qtd_nulos/total_linhas*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d613432-fcf4-4af9-a292-a7cbcd3523e2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Função para realizar a ingestão de dados"
    }
   },
   "outputs": [],
   "source": [
    "def ingestao_dados(dados, table_name, schema):\n",
    "    \n",
    "    # Leitura dos dados da tabela existente (caso já tinha sido salva anteriormente)\n",
    "    dados_existentes = spark.read.table(f\"{schema}_layer.{table_name}\");\n",
    "    \n",
    "    # Verificando se os dados importados já existem\n",
    "    verifica_tabela = spark.catalog.tableExists(f\"{schema}_layer.{table_name}\");\n",
    "\n",
    "    # Se a tabela já existir, realiza filtragem no dataframe importado para inserir apenas os dados novos\n",
    "    if verifica_tabela:         \n",
    "\n",
    "        colunas = dados.columns\n",
    "\n",
    "        condicoes = [dados[c] == dados_existentes[c] for c in colunas]\n",
    "\n",
    "        df_filtrado = dados.join(dados_existentes, on=condicoes, how=\"left_anti\")\n",
    "        \n",
    "        df_filtrado = df_filtrado.dropDuplicates()\n",
    "\n",
    "        print('>> Camada: Silver')\n",
    "        print(f'>> Caminho da tabela bronze: bronze_layer.{table_name}')\n",
    "        print('>>> Executando carga de dados...', end=\" \")\n",
    "\n",
    "        try:        \n",
    "            save_table(df_filtrado, table_name, 'silver')\n",
    "            print('CARGA FINALIZADA COM SUCESSO! \\n')\n",
    "        except:\n",
    "            print('ERRO NA CARGA DE DADOS... \\n')    \n",
    "\n",
    "    # Caso a tabela não exista, realiza a carga dos dados pela primeira vez\n",
    "    else:        \n",
    "        \n",
    "        print('>> Camada: Silver')\n",
    "        print(f'>> Caminho da tabela bronze: bronze_layer.{table_name}')\n",
    "        print('>>> Executando carga de dados...', end=\" \")\n",
    "\n",
    "        dados = dados.dropDuplicates()\n",
    "\n",
    "        try:        \n",
    "            save_table(dados, table_name, 'silver')\n",
    "            print('CARGA FINALIZADA COM SUCESS! \\n')\n",
    "        except:\n",
    "            print('ERRO NA CARGA DE DADOS... \\n')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9350687-2b6d-4a67-8d15-4fb9882ef235",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Função para análise da qualidade dos dados"
    }
   },
   "outputs": [],
   "source": [
    "def analise_qualidade_dados(df):\n",
    "\n",
    "    # Filtro de registros com ano inválido\n",
    "    print('>>> A coluna ANO_DO_EXERCICIO não pode estar fora do intervalo entre 1900 e o ano atual. Verificando...\\n')\n",
    "    \n",
    "    print(f'Qtd de registros com ANO_DO_EXERCICIO inválido: {df.filter((col('ANO_DO_EXERCICIO') < 1900) | (col('ANO_DO_EXERCICIO') > year(current_date()))).count()}')\n",
    "\n",
    "    print('Filtrando registros com ANO_DO_EXERCICIO fora do intervalo entre 1900 e o ano atual...', end=\" \")\n",
    "\n",
    "    df = df.filter(~((col('ano do exercício') < 1900) | (col('ano do exercício') > year(current_date()))))\n",
    "    print('OK!\\n')\n",
    "\n",
    "    # Filtro de registros com CEP inválido\n",
    "    print('>>> Para ser válido, o CEP não pode ter valor nulo e deve possuir 8 dígitos. Verificando...\\n')\n",
    "    \n",
    "    print(f'Qtd de registros com CEP inválido: {df.filter(col('CEP').isNotNull() & (col('CEP') < 10000000) | (col('CEP') > 99999999)).count()}')\n",
    "\n",
    "    print('Filtrando registros com CEP inválido...', end=\" \")\n",
    "\n",
    "    df = df.filter(~(col('CEP').isNotNull() & (col('CEP') < 10000000) | (col('CEP') > 99999999)))\n",
    "\n",
    "    print('OK!\\n')\n",
    "\n",
    "    # Filtro de registros em que o valor do IPTU é maior do que o valor do imóvel (dados inconsistentes)\n",
    "    print('>>> O IPTU do imóvel não pode ser maior do que o valor do próprio imóvel. Verificando...\\n')\n",
    "    \n",
    "    print(f'Qtd de registros com IPTU maior do que o valor do imóvel: {df.filter(col('VALOR_COBRADO_DE_IPTU') > col('VALOR_TOTAL_DO_IMOVEL_ESTIMADO')).count()}')\n",
    "\n",
    "    print('Filtrando registros em que o valor do IPTU é maior do que o valor do imóvel (dados inconsistentes)...', end=\" \")\n",
    "\n",
    "    df = df.filter(col('VALOR_COBRADO_DE_IPTU') < col('VALOR_TOTAL_DO_IMOVEL_ESTIMADO'))\n",
    "\n",
    "    print('OK!\\n')\n",
    "\n",
    "    # Filtro de registros com inconsistência no preenchimento da coluna ESTADO\n",
    "    print('>>> A coluna que tem a informação do ESTADO deve possuir apenas 2 caracteres com letras. Verificando...\\n')\n",
    "\n",
    "    print(f'Qtd de registros com inconsistência na coluna ESTADO: {df.filter(col('ESTADO').isNotNull() & (col('ESTADO').rlike(\"^[A-Z]{2}$\") == False)).count()}')\n",
    "\n",
    "    print('Filtrando registros com inconsistências no preenchimento da coluna ESTADO...', end=\" \")\n",
    "\n",
    "    df = df.filter(col('ESTADO').isNotNull() & (col('ESTADO').rlike(\"^[A-Z]{2}$\") == True))\n",
    "\n",
    "    print('OK!\\n')\n",
    "\n",
    "    # Filtro de registros com valor de IPTU menor ou igual a zero\n",
    "    print('>>> O valor do IPTU do imóvel deve ser maior do que zero. Verificando...\\n')\n",
    "\n",
    "    print(f'Qtd de registros com valor de IPTU menor ou igual a zero: {df.filter(col('VALOR_COBRADO_DE_IPTU') <= 0).count()}')\n",
    "\n",
    "    print('Filtrando registros com valor de IPTU menor ou igual a zero...', end=\" \")\n",
    "    df = df.filter(col('VALOR_COBRADO_DE_IPTU') > 0)\n",
    "\n",
    "    print('OK!')\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}